import asyncio
from typing import List, Dict
from fuzzywuzzy import fuzz
from .naver_news_service import naver_news_service
from .keyword_filter_service import keyword_filter_service
from .classifier_service import classifier_service
from .summary_service import summary_service

class NewsPipelineService:
    def __init__(self):
        self.naver_service = naver_news_service
        self.keyword_filter = keyword_filter_service
        self.classifier = classifier_service
        self.summary = summary_service
    
    def remove_similar_titles(self, news_list: List[Dict]) -> List[Dict]:
        """
        ìœ ì‚¬í•œ ì œëª©ì„ ê°€ì§„ ë‰´ìŠ¤ë“¤ì„ ì œê±°í•˜ì—¬ ì¤‘ë³µ ê¸°ì‚¬ë¥¼ ì¤„ì…ë‹ˆë‹¤.
        fuzzywuzzy token_set_ratioë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ì–´ìˆœ/ì¡°ì‚¬ ë³€í™”ì— ê°•í•œ ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            news_list: ë‰´ìŠ¤ ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìœ ì‚¬í•œ ì œëª©ì„ ì œê±°í•œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        if not news_list:
            return news_list
        
        original_count = len(news_list)
        filtered_news = []
        similarity_threshold = 85
        
        for current_news in news_list:
            current_title = current_news.get("title", "").strip()
            if not current_title:
                continue
            
            # ì´ë¯¸ ì¶”ê°€ëœ ë‰´ìŠ¤ë“¤ê³¼ ìœ ì‚¬ë„ ë¹„êµ
            is_similar = False
            for existing_news in filtered_news:
                existing_title = existing_news.get("title", "").strip()
                
                # fuzzywuzzy token_set_ratioë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
                similarity_score = fuzz.token_set_ratio(current_title, existing_title)
                
                if similarity_score >= similarity_threshold:
                    is_similar = True
                    break
            
            # ìœ ì‚¬í•˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
            if not is_similar:
                filtered_news.append(current_news)
        
        print(f"ğŸ§¹ ìœ ì‚¬ ì œëª© ì œê±° ê²°ê³¼: {len(filtered_news)}/{original_count}ê°œ")
        return filtered_news
    
    async def process_news_pipeline(self, companies: List[str]) -> Dict:
        """
        ì „ì²´ ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
        1. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
        2. í‚¤ì›Œë“œ 1ì°¨ í•„í„°ë§
        3. AI ëª¨ë¸ 2ì°¨ ë¶„ë¥˜
        4. ìš”ì•½ ìƒì„±
        """
        print(f"ğŸ¤3 ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì„œë¹„ìŠ¤ ì§„ì… - ê¸°ì—… ìˆ˜: {len(companies)}")
        
        try:
            # 1ë‹¨ê³„: ëª¨ë“  ê¸°ì—…ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘
            print("ğŸ“° 1ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            all_news = []
            
            # ë™ì‹œì— ëª¨ë“  ê¸°ì—… ë‰´ìŠ¤ ìˆ˜ì§‘
            tasks = [self.naver_service.fetch_news_for_company(company) for company in companies]
            news_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in news_results:
                if isinstance(result, list):
                    all_news.extend(result)
                else:
                    print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {result}")
            
            print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘")
            
            if not all_news:
                return {
                    "status": "success",
                    "message": "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "total_collected": 0,
                    "after_keyword_filter": 0,
                    "after_classification": 0,
                    "final_summaries": 0,
                    "results": []
                }
            
            # 2ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ í•„í„°ë§
            print("ğŸ” 2ë‹¨ê³„: í‚¤ì›Œë“œ í•„í„°ë§ ì‹œì‘")
            keyword_filtered_news = self.keyword_filter.filter_by_keywords(all_news)
            
            if not keyword_filtered_news:
                return {
                    "status": "success",
                    "message": "í‚¤ì›Œë“œ í•„í„°ë§ì„ í†µê³¼í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "total_collected": len(all_news),
                    "after_keyword_filter": 0,
                    "after_deduplication": 0,
                    "after_classification": 0,
                    "final_summaries": 0,
                    "results": []
                }
            
            # 2.5ë‹¨ê³„: ìœ ì‚¬í•œ ì œëª© ì œê±°
            print("ğŸ§¹ 2.5ë‹¨ê³„: ìœ ì‚¬ ì œëª© ì œê±° ì‹œì‘")
            deduped_news = self.remove_similar_titles(keyword_filtered_news)
            
            if not deduped_news:
                return {
                    "status": "success",
                    "message": "ìœ ì‚¬ ì œëª© ì œê±° í›„ ë‚¨ì€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "total_collected": len(all_news),
                    "after_keyword_filter": len(keyword_filtered_news),
                    "after_deduplication": 0,
                    "after_classification": 0,
                    "final_summaries": 0,
                    "results": []
                }
            
            # 3ë‹¨ê³„: AI ëª¨ë¸ 2ì°¨ ë¶„ë¥˜
            print("ğŸ¤– 3ë‹¨ê³„: AI ë¶„ë¥˜ ì‹œì‘")
            classified_news = await self.classifier.classify_news(deduped_news)
            
            if not classified_news:
                return {
                    "status": "success",
                    "message": "AI ë¶„ë¥˜ë¥¼ í†µê³¼í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "total_collected": len(all_news),
                    "after_keyword_filter": len(keyword_filtered_news),
                    "after_deduplication": len(deduped_news),
                    "after_classification": 0,
                    "final_summaries": 0,
                    "results": []
                }
            
            # 4ë‹¨ê³„: ìš”ì•½ ìƒì„±
            print("ğŸ“ 4ë‹¨ê³„: ìš”ì•½ ìƒì„± ì‹œì‘")
            final_results = await self.summary.summarize_news(classified_news)
            
            # ê²°ê³¼ ì •ë¦¬
            pipeline_result = {
                "status": "success",
                "message": "ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ",
                "total_collected": len(all_news),
                "after_keyword_filter": len(keyword_filtered_news),
                "after_deduplication": len(deduped_news),
                "after_classification": len(classified_news),
                "final_summaries": len(final_results),
                "companies_processed": companies,
                "results": final_results
            }
            
            print(f"ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ìµœì¢… {len(final_results)}ê°œ ìš”ì•½ ìƒì„±")
            return pipeline_result
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "status": "error",
                "message": f"íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "total_collected": 0,
                "after_keyword_filter": 0,
                "after_deduplication": 0,
                "after_classification": 0,
                "final_summaries": 0,
                "results": []
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
news_pipeline_service = NewsPipelineService() 